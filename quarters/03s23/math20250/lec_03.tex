\lecture{3}{30 Mar 2023}{Vector Spaces}

\subsection{Elementary Row Operations and Systems of Linear Equations}
\textbf{Question:} What are we doing to the matrices \(A, B (Ax = B)\) (\(A\) of size \(m \times n\), \(B\) of size \(n \times 1\)) when elementary row operations are carried out?

\textbf{Answer:} The row operations operate on the \textbf{rows} of \(A\) (switching rows, multiplying by scalar, adding other rows)

\begin{example}
    \[
        A_0 = \left[\begin{array}{ccc}
                2 & 1 & 1 \\
                1 & 2 & 3 \\
                1 & 1 & 1
            \end{array}\right]
        \overset{(1') = (1) + -2(3)}{\sim}
        A_1 = \left[\begin{array}{ccc}
                0 & -1 & -1 \\
                1 & 2  & 3  \\
                1 & 1  & 1
            \end{array}\right]
        \sim \dots \sim
        A_7 = \left[\begin{array}{ccc}
                1 & 0 & 0 \\
                0 & 1 & 0 \\
                0 & 0 & 1
            \end{array}\right]
    \]
    \[
        \left[\begin{array}{ccc}
                1 & 0 & 0 \\
                0 & 1 & 0 \\
                0 & 0 & 1
            \end{array}\right]
        \left[\begin{array}{c}
                x_1 \\
                x_2 \\
                x_3
            \end{array}\right] =
        \left[\begin{array}{c}
                b \dots \\
                b \dots \\
                b \dots
            \end{array}\right]
    \]

    We eventually arrived \(LHS = \left[\begin{array}{c}
            x_1 \\
            x_2 \\
            x_3
        \end{array}\right]\) itself, due to the properties of \(I_3\). By ``simplying'' rows this way, we can therefore solve systems of linear equations.
\end{example}

\begin{definition} [Row-reduced Matrix]
    The \textbf{row-reduced} form of a matrix has 1 as the leading non-zero coefficient for each of its rows (0-padded on the left). Furthermore, each column which contains the leading non-zero entry of some row has all its other entries as 0. By convention, the leading coefficient of a row of higher row index also has a higher column index.
\end{definition}

\begin{proof}{Proposition~\ref{prop:2.2}}
    We only provide a sketch of the proof. We re-enumerate the types of operations:
    \begin{enumerate}
        \item \((i) \leftrightarrow (j)\)
        \item \((i) \rightarrow c(i), c \neq 0\)
        \item \((i) \rightarrow (i) + d(j), j \neq i\)
    \end{enumerate}
    Explanations:
    \begin{enumerate}
        \item Trivial
        \item Clearly \(S'\) is obtainable from \(S\), and trivially all other equations except for \((i)\) of \(S\) are obtainable from \(S'\). However, \((i) = c^{-1}(c(i)) = c^{-1}(i')\). Therefore \(S \sim S'\).
        \item Similarly, \(S'\) is clearly obtainable from \(S\), while \((i) = (i') - d(j) = (i') - d(j')\). Therefore \(S \sim S'\).
    \end{enumerate}
\end{proof}

\subsection{Vector Spaces}
\begin{definition} [Vector Space]
    Let \(\bbk\) be a field. A \textbf{vector space over \(\bbk\)} (``\(\bbk\)-vector space'')(``k-vs'') is an Abelian group \(V\) with a map: \(\bbk \times V \to V\) (\(\bbk\)-action on \(V\)). An element in \(V\) is called a \textbf{vector}. They have to satisfy \(\forall a, b \in \bbk; \forall v, v_1, v_2 \in V\):
    \begin{enumerate}
        \item \(0 \cdot v = 0\\ 1 \cdot v = v\)
        \item \((a + b) \cdot v = (a \cdot v) + (b \cdot v)\\ (a \cdot b) \cdot v = a \cdot (b \cdot v)\)
        \item \(a \cdot (v_1 +  v_2) = (a \cdot v_1) + (a \cdot v_2)\)
    \end{enumerate}

    Essentially, \(\bbk, V\) with operations:
    \begin{enumerate}
        \item \(+: \bbk \times \bbk \to \bbk, \cdot: \bbk \times \bbk \to \bbk\) (Field)
        \item \(+: V \times V \to V\) (Abelian group)
        \item \(\cdot: \bbk \times V \to V\) (Action)
    \end{enumerate}
\end{definition}

\begin{example}
    Field \(\bbk = \bbr\), \(V = \bbr^n \doteq \{(x_1, x_2, \dots, x_n) \mid x_i \in \bbr\}\). Indeed, \(\bbr^n\) is an Abelian group.
\end{example}

\begin{definition} [Linear Combination]
    Let \(V\) be a k-vs. If \(v_1, v_2, \dots, v_r \in V; r \in \bbn\) then a \textbf{linear combination} of \(\{v_1, v_2, \dots, v_r\}\) is a vector of the form \[
        c_1 \cdot v_1 + c_2 \cdot v_2 + \dots + c_r \cdot v_r \:\text{where}\: c_i \in \bbk
    \]
\end{definition}

\begin{definition} [Linear Span]
    Then the \textbf{linear span} of \(v_1, v_2, \dots, v_r \:\text{in}\: V\) is the set of all such linear combinations.
\end{definition}

